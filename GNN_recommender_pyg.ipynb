{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSTALATION #######\n",
    "\n",
    "!pip uninstall torch -y\n",
    "!pip install torch==1.13.1\n",
    "# !pip uninstall torch-scatter -y\n",
    "# !pip uninstall torch-sparse -y\n",
    "# !pip uninstall pyg-lib -y\n",
    "# !pip uninstall git+https://github.com/pyg-team/pytorch_geometric.git -y\n",
    "# !pip uninstall sentence_transformers -y\n",
    "\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
    "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install pyarrow fastparquet\n",
    "!pip install transformers\n",
    "!pip install lightfm\n",
    "!pip install memory-profiler\n",
    "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "# !pip install sentence_transformers==0.1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1216.3671875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = psutil.Process(os.getpid())\n",
    "mem_usage_before = process.memory_info().rss / (1024 * 1024)\n",
    "mem_usage_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### IMPORT #######\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "# from neo4j import GraphDatabase\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "import pickle\n",
    "from memory_profiler import profile\n",
    "# from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SETUP ARGS ###########\n",
    "len_interactions_to_consider = 100000\n",
    "each_user_all2all_new_edges = 100 # when running sBERT, we have the embedding saved for 100k contracts\n",
    "dataset_mode = 'movie'\n",
    "\n",
    "possible_experiments = {\n",
    "    0: 'all',\n",
    "    1: 'diversity',\n",
    "    2: 'ucsp',\n",
    "    3: 'icsp',\n",
    "    4: 'usparsity',\n",
    "    5: 'isparsity',\n",
    "    9: 'add_social_edges',\n",
    "}\n",
    "experiment = possible_experiments[0]\n",
    "possible_modes = ['debug', 'experiment']\n",
    "mode = possible_modes[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file ml-latest-small.zip\n",
      "Extracting ./ml-latest-small.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items 998\n",
      "number of users 589\n",
      "avg number of interactions per user 17.365025466893037\n"
     ]
    }
   ],
   "source": [
    "#### DATA LOADER ####\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch import Tensor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def data_loader(ratings_df):\n",
    "    unique_user_id = ratings_df['userId'].unique()\n",
    "    unique_user_id = pd.DataFrame(data={\n",
    "        'userId': unique_user_id,\n",
    "        'mappedID': pd.RangeIndex(len(unique_user_id)),\n",
    "    })\n",
    "    # print(\"Mapping of user IDs to consecutive values:\")\n",
    "    # print(\"==========================================\")\n",
    "    # print(unique_user_id.head())\n",
    "\n",
    "    unique_item_id = ratings_df['itemId'].unique()\n",
    "    unique_item_id = pd.DataFrame(data={\n",
    "        'itemId': unique_item_id,\n",
    "        'mappedID': pd.RangeIndex(len(unique_item_id)),\n",
    "    })\n",
    "    # print(\"Mapping of item IDs to consecutive values:\")\n",
    "    # print(\"===========================================\")\n",
    "    # print(unique_item_id.head())\n",
    "\n",
    "    ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id,\n",
    "                                left_on='userId', right_on='userId', how='left')\n",
    "    ratings_user_id = torch.from_numpy(ratings_user_id['mappedID'].values)\n",
    "    ratings_item_id = pd.merge(ratings_df['itemId'], unique_item_id,\n",
    "                                left_on='itemId', right_on='itemId', how='left')\n",
    "    ratings_item_id = torch.from_numpy(ratings_item_id['mappedID'].values)\n",
    "    edge_index_user_to_item = torch.stack([ratings_user_id, ratings_item_id], dim=0)\n",
    "    # print()\n",
    "    # print(\"Final edge indices pointing from users to items:\")\n",
    "    # print(\"=================================================\")\n",
    "    # print(edge_index_user_to_item)\n",
    "    return unique_user_id, unique_item_id, edge_index_user_to_item\n",
    "\n",
    "def movie_loader():\n",
    "    # url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "    url = 'https://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "    extract_zip(download_url(url, '.'), '.')\n",
    "    movies_path = './ml-latest-small/movies.csv'\n",
    "    ratings_path = './ml-latest-small/ratings.csv'\n",
    "    items_ratings_df = pd.read_csv(ratings_path)\n",
    "    items_ratings_df = items_ratings_df.rename(columns={'movieId': 'itemId'})\n",
    "    unique_user_id, unique_item_id, edge_index_user_to_item = data_loader(items_ratings_df)\n",
    "    items_df = pd.read_csv(movies_path)\n",
    "    items_df = items_df.rename(columns={'movieId': 'itemId', 'title': 'name'})\n",
    "    items_df = pd.merge(items_df, unique_item_id, on='itemId', how='left')\n",
    "    items_df = items_df.sort_values('mappedID') # (Just the last 20 movies have NaN mappedId)\n",
    "    genres = items_df['genres'].str.get_dummies('|')\n",
    "    print(genres[[\"Action\", \"Adventure\", \"Drama\", \"Horror\"]].head())\n",
    "    item_feat_movielens = torch.from_numpy(genres.values).to(torch.float)\n",
    "    assert item_feat_movielens.size() == (9742, 20)  # 20 genres in total.\n",
    "\n",
    "    item_feat_zeros = torch.zeros_like(item_feat_movielens)\n",
    "    item_feats_dict = {\n",
    "        'item_feat_zeros': item_feat_zeros, \n",
    "        'item_feat_movielens': item_feat_movielens\n",
    "        }\n",
    "    \n",
    "    return unique_user_id, unique_item_id, edge_index_user_to_item, items_df, item_feat_zeros, item_feats_dict, items_ratings_df\n",
    "\n",
    "def movie_loader_sparse(k):\n",
    "    # url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "    url = 'https://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "    extract_zip(download_url(url, '.'), '.')\n",
    "    movies_path = './ml-latest-small/movies.csv'\n",
    "    ratings_path = './ml-latest-small/ratings.csv'\n",
    "    items_ratings_df = pd.read_csv(ratings_path)\n",
    "    items_ratings_df = items_ratings_df.rename(columns={'movieId': 'itemId'})\n",
    "    items_df = pd.read_csv(movies_path)\n",
    "    items_df = items_df.rename(columns={'movieId': 'itemId', 'title': 'name'})\n",
    "    items_ratings_df = items_ratings_df.groupby('userId').apply(lambda x: x.sample(frac=k/100)).reset_index(drop=True)\n",
    "    valid_item_ids = items_ratings_df['itemId'].unique()\n",
    "    items_df = items_df[items_df['itemId'].isin(valid_item_ids)]\n",
    "    unique_user_id, unique_item_id, edge_index_user_to_item = data_loader(items_ratings_df)\n",
    "    items_df = pd.merge(items_df, unique_item_id, on='itemId', how='left')\n",
    "    items_df = items_df.sort_values('mappedID')\n",
    "    genres = items_df['genres'].str.get_dummies('|')\n",
    "    item_feat_movielens = torch.from_numpy(genres.values).to(torch.float)\n",
    "    #TODO: change the 20 to be dynamically changed based on fetures\n",
    "    assert item_feat_movielens.size() == (len(valid_item_ids), 20)  # 20 genres in total.\n",
    "    item_feat_zeros = torch.zeros(len(valid_item_ids), 20)\n",
    "    item_feats_dict = {\n",
    "        'item_feat_zeros': item_feat_zeros, \n",
    "        'item_feat_movielens': item_feat_movielens\n",
    "        }\n",
    "\n",
    "    return unique_user_id, unique_item_id, edge_index_user_to_item, items_df, item_feat_zeros, item_feats_dict, items_ratings_df\n",
    "\n",
    "def movie_loader_sampling_user(num_users, k):\n",
    "    url = 'https://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "    extract_zip(download_url(url, '.'), '.')\n",
    "    movies_path = './ml-latest-small/movies.csv'\n",
    "    ratings_path = './ml-latest-small/ratings.csv'\n",
    "    items_ratings_df = pd.read_csv(ratings_path)\n",
    "    items_ratings_df = items_ratings_df.rename(columns={'movieId': 'itemId'})\n",
    "    selected_users = np.random.choice(items_ratings_df['userId'].unique(), num_users, replace=False)\n",
    "    filtered_df = items_ratings_df[items_ratings_df['userId'].isin(selected_users)]\n",
    "    items_ratings_df = filtered_df.groupby('userId').apply(lambda x: x.sample(frac=k/100)).reset_index(drop=True)\n",
    "    items_df = pd.read_csv(movies_path)\n",
    "    items_df = items_df.rename(columns={'movieId': 'itemId', 'title': 'name'})\n",
    "    valid_item_ids = items_ratings_df['itemId'].unique()\n",
    "    items_df = items_df[items_df['itemId'].isin(valid_item_ids)]\n",
    "    unique_user_id, unique_item_id, edge_index_user_to_item = data_loader(items_ratings_df)\n",
    "    items_df = pd.merge(items_df, unique_item_id, on='itemId', how='left')\n",
    "    items_df = items_df.sort_values('mappedID')\n",
    "    genres = items_df['genres'].str.get_dummies('|')\n",
    "    item_feat_movielens = torch.from_numpy(genres.values).to(torch.float)\n",
    "\n",
    "    # Verify the number of genres (20 is assumed here)\n",
    "    assert item_feat_movielens.size() == (len(valid_item_ids), item_feat_movielens.shape[1])\n",
    "\n",
    "    item_feat_zeros = torch.zeros(len(valid_item_ids), item_feat_movielens.shape[1])\n",
    "\n",
    "    item_feats_dict = {\n",
    "        'item_feat_zeros': item_feat_zeros,\n",
    "        'item_feat_movielens': item_feat_movielens\n",
    "    }\n",
    "\n",
    "    return unique_user_id, unique_item_id, edge_index_user_to_item, items_df, item_feat_zeros, item_feats_dict, items_ratings_df\n",
    "\n",
    "def movie_loader_sampling_movie(num_movies):\n",
    "    url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "    extract_zip(download_url(url, '.'), '.')\n",
    "    movies_path = './ml-latest-small/movies.csv'\n",
    "    ratings_path = './ml-latest-small/ratings.csv'\n",
    "\n",
    "    items_df = pd.read_csv(movies_path)\n",
    "    items_df = items_df.rename(columns={'movieId': 'itemId'})\n",
    "    items_ratings_df = pd.read_csv(ratings_path)\n",
    "    items_ratings_df = items_ratings_df.rename(columns={'movieId': 'itemId'})\n",
    "    selected_movies = items_df.sample(n=num_movies, random_state=42)  # Adjust random_state for reproducibility if needed\n",
    "    items_ratings_df = items_ratings_df[items_ratings_df['itemId'].isin(selected_movies['itemId'])]\n",
    "\n",
    "    valid_item_ids = selected_movies['itemId'].unique()\n",
    "    items_df = items_df[items_df['itemId'].isin(valid_item_ids)]\n",
    "    unique_user_id, unique_item_id, edge_index_user_to_item = data_loader(items_ratings_df)\n",
    "    items_df = pd.merge(items_df, unique_item_id, on='itemId', how='left')\n",
    "    items_df = items_df.sort_values('mappedID')\n",
    "\n",
    "    genres = items_df['genres'].str.get_dummies('|')\n",
    "    item_feat_movielens = torch.from_numpy(genres.values).to(torch.float)\n",
    "    assert item_feat_movielens.size() == (len(valid_item_ids), 20)  # Verify the size based on genre features\n",
    "\n",
    "    item_feat_zeros = torch.zeros(len(valid_item_ids), 20)\n",
    "    item_feats_dict = {\n",
    "        'item_feat_zeros': item_feat_zeros, \n",
    "        'item_feat_movielens': item_feat_movielens\n",
    "    }\n",
    "\n",
    "    return unique_user_id, unique_item_id, edge_index_user_to_item, items_df, item_feat_zeros, item_feats_dict, items_ratings_df\n",
    "\n",
    "def movie_loader_sampling_popular(num_items):\n",
    "    url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "    extract_zip(download_url(url, '.'), '.')\n",
    "    movies_path = './ml-latest-small/movies.csv'\n",
    "    ratings_path = './ml-latest-small/ratings.csv'\n",
    "\n",
    "    items_df = pd.read_csv(movies_path)\n",
    "    items_df = items_df.rename(columns={'movieId': 'itemId'})\n",
    "    items_ratings_df = pd.read_csv(ratings_path)\n",
    "    items_ratings_df = items_ratings_df.rename(columns={'movieId': 'itemId'})\n",
    "\n",
    "    popular_movies = items_ratings_df['itemId'].value_counts().head(num_items).index\n",
    "    items_ratings_df = items_ratings_df[items_ratings_df['itemId'].isin(popular_movies)]\n",
    "\n",
    "    items_ratings_df = items_ratings_df.groupby('userId').apply(lambda x: x.sample(frac=10/100)).reset_index(drop=True)\n",
    "\n",
    "    valid_item_ids = items_df[items_df['itemId'].isin(popular_movies)]['itemId'].unique()\n",
    "    items_df = items_df[items_df['itemId'].isin(valid_item_ids)]\n",
    "    unique_user_id, unique_item_id, edge_index_user_to_item = data_loader(items_ratings_df)\n",
    "    items_df = pd.merge(items_df, unique_item_id, on='itemId', how='left')\n",
    "    items_df = items_df.sort_values('mappedID')\n",
    "\n",
    "    genres = items_df['genres'].str.get_dummies('|')\n",
    "    item_feat_movielens = torch.from_numpy(genres.values).to(torch.float)\n",
    "    assert item_feat_movielens.size() == (len(valid_item_ids), item_feat_movielens.shape[1])  # Verify the size based on genre features\n",
    "\n",
    "    item_feat_zeros = torch.zeros(len(valid_item_ids), 20)\n",
    "    item_feats_dict = {\n",
    "        # 'item_feat_zeros': item_feat_zeros, \n",
    "        'item_feat_movielens': item_feat_movielens\n",
    "    }\n",
    "\n",
    "    return unique_user_id, unique_item_id, edge_index_user_to_item, items_df, item_feat_zeros, item_feats_dict, items_ratings_df\n",
    "\n",
    "def selective_sampling(x):\n",
    "    url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "    extract_zip(download_url(url, '.'), '.')\n",
    "    movies_path = './ml-latest-small/movies.csv'\n",
    "    ratings_path = './ml-latest-small/ratings.csv'\n",
    "\n",
    "    items_df = pd.read_csv(movies_path)\n",
    "    items_df = items_df.rename(columns={'movieId': 'itemId'})\n",
    "    items_ratings_df = pd.read_csv(ratings_path)\n",
    "    items_ratings_df = items_ratings_df.rename(columns={'movieId': 'itemId'})\n",
    "\n",
    "    # Select x interactions for each user\n",
    "    items_ratings_df = items_ratings_df.groupby('userId').apply(lambda grp: grp.sample(n=min(len(grp), x), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "    # Iteratively remove interactions with the least popular items\n",
    "    while True:\n",
    "        item_popularity = items_ratings_df['itemId'].value_counts()\n",
    "        least_popular_item = item_popularity.idxmin()\n",
    "        items_ratings_df = items_ratings_df[items_ratings_df['itemId'] != least_popular_item]\n",
    "\n",
    "        num_users = len(items_ratings_df['userId'].unique())\n",
    "        num_items = len(items_ratings_df['itemId'].unique())\n",
    "\n",
    "        # Check if the ratio of users to items falls below 0.5, then break\n",
    "        if num_users / num_items < 0.5:\n",
    "            break\n",
    "\n",
    "    valid_item_ids = items_df[items_df['itemId'].isin(items_ratings_df['itemId'])]['itemId'].unique()\n",
    "    items_df = items_df[items_df['itemId'].isin(valid_item_ids)]\n",
    "    unique_user_id, unique_item_id, edge_index_user_to_item = data_loader(items_ratings_df)\n",
    "    items_df = pd.merge(items_df, unique_item_id, on='itemId', how='left')\n",
    "    items_df = items_df.sort_values('mappedID')\n",
    "\n",
    "    genres = items_df['genres'].str.get_dummies('|')\n",
    "    item_feat_movielens = torch.from_numpy(genres.values).to(torch.float)\n",
    "    assert item_feat_movielens.size() == (len(valid_item_ids), item_feat_movielens.shape[1])  # Verify the size based on genre features\n",
    "\n",
    "    item_feat_zeros = torch.zeros(len(valid_item_ids), 20)\n",
    "    item_feats_dict = {\n",
    "        'item_feat_zeros': item_feat_zeros, \n",
    "        'item_feat_movielens': item_feat_movielens\n",
    "    }\n",
    "\n",
    "    return unique_user_id, unique_item_id, edge_index_user_to_item, items_df, item_feat_zeros, item_feats_dict, items_ratings_df\n",
    "\n",
    "def contract_loader():\n",
    "    items_ratings_df = pd.read_parquet('dataset/user_contract_rating.parquet')\n",
    "    items_ratings_df = items_ratings_df[:len_interactions_to_consider] if mode == 'debug' else items_ratings_df #$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "    #TODO: Shuffle the interactions, and see still for higher folds the result degrade for CF_GNN or not\n",
    "    \n",
    "    def calculate_sparcity_value(df):\n",
    "        num_users = df['user'].nunique()\n",
    "        num_items = df['item'].nunique()\n",
    "        num_interactions = len(df)\n",
    "        total_possible_interactions = num_users * num_items / 100\n",
    "        sparsity = 1 - (num_interactions / total_possible_interactions)\n",
    "        return sparsity\n",
    "    \n",
    "    def filter_interactions(df, column, k):\n",
    "        valid_entries = df[column].value_counts()\n",
    "        valid_entries = valid_entries[valid_entries >= k]\n",
    "        df = df[df[column].isin(valid_entries.index)]\n",
    "        print(f'{column} sparcity value is:', calculate_sparcity_value(df))\n",
    "        return df\n",
    "\n",
    "    ########## SPARCITY EXPERIMENT ###########\n",
    "    if experiment == 'usparsity':\n",
    "        u = 1\n",
    "        items_ratings_df = filter_interactions(items_ratings_df, 'user', u)\n",
    "    elif experiment == 'isparsity':\n",
    "        i = 20\n",
    "        items_ratings_df = filter_interactions(items_ratings_df, 'item', i)\n",
    "\n",
    "    items_df = {}\n",
    "    items_df['name'] = items_ratings_df['item'].unique()\n",
    "    items_df['itemId'], unique_names = pd.factorize(items_df['name'])\n",
    "    # items_df['itemId'] = items_df['itemId'] + 1 #TODO test commenting this line didn't breal anything\n",
    "    items_df = pd.DataFrame(items_df, columns=['itemId', 'name'])\n",
    "\n",
    "    def get_item_feat_sbert(items_df):\n",
    "        contract2comments = pd.read_parquet('dataset/contracts2comment.parquet')\n",
    "        c2c_main_class = contract2comments[contract2comments['contract_name'] == contract2comments['class_name']]\n",
    "\n",
    "        def reorder_text(text):\n",
    "            lines = text.split(\"\\n\")\n",
    "            notice_lines = [line for line in lines if \"@notice\" in line]\n",
    "            other_lines = [line for line in lines if \"@notice\" not in line]\n",
    "            reorderd_text = \"\\n\".join(notice_lines + other_lines)\n",
    "            return reorderd_text\n",
    "\n",
    "        def preprocess_text(text):\n",
    "            text = reorder_text(text)\n",
    "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "            # Remove special characters, numbers, etc.\n",
    "            text = re.sub(r'\\W', ' ', text)\n",
    "            # Remove extra spaces\n",
    "            text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            text = text[:512] if len(text) > 512 else text\n",
    "            return text\n",
    "\n",
    "        sentences = []\n",
    "        for i, item in items_df.iterrows():\n",
    "            comment_class = c2c_main_class[c2c_main_class['contract_name'] == item['name']]\n",
    "            if not comment_class.empty and comment_class['class_documentation'].iloc[0] != '':\n",
    "                sentences.append(comment_class['class_documentation'].iloc[0])\n",
    "            else:\n",
    "                class_names = contract2comments[contract2comments['contract_name'] == item['name']]['class_name']\n",
    "                sentences.append(' '.join(class_names))\n",
    "\n",
    "        preprocessed_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/bert-base-nli-mean-tokens\")\n",
    "        model = AutoModel.from_pretrained(\"sentence-transformers/bert-base-nli-mean-tokens\")\n",
    "        device = torch.device(\"cpu\") #\"cuda\" if torch.cuda.is_available() else \"cpu\") # NOT enough GPU memory\n",
    "        model = model.to(device)\n",
    "        inputs = tokenizer(preprocessed_sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "        inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        item_feat = embeddings\n",
    "        # model = SentenceTransformer('sentence-transformers/distilbert-base-nli-mean-tokens')\n",
    "        # embeddings = model.encode(preprocessed_sentences)\n",
    "        \n",
    "        return item_feat\n",
    "    \n",
    "    def get_item_feat_tfidf(items_df):\n",
    "        contract_top_words_df = pd.read_parquet('dataset/contract_top_words.parquet')\n",
    "        contract_top_words_df = contract_top_words_df.rename(columns={'contract_name': 'name'})\n",
    "        contracts_df_top_words = items_df.merge(contract_top_words_df, on='name', how='left')\n",
    "        contracts_df_top_words['keywords'] = contracts_df_top_words['keywords'].fillna('')\n",
    "        items_df = contracts_df_top_words\n",
    "        items_df.set_index('itemId', inplace=True)\n",
    "        # f =5 # ratio to determine the number of top keywords selected for each contract to construct item_feat\n",
    "        items_df['truncated_keywords'] = items_df['keywords'].apply(lambda x: ','.join(x.split(',')))\n",
    "        X_df = items_df['truncated_keywords'].str.get_dummies(',')\n",
    "        item_feat = torch.from_numpy(X_df.values).to(torch.float)\n",
    "        return item_feat\n",
    "    \n",
    "    def get_item_feat_clustering(items_df):\n",
    "        contract_to_topic_df = pd.read_parquet(\"dataset/contract_name_topic.parquet\")\n",
    "        items_df = pd.merge(items_df, contract_to_topic_df, left_on='name', right_on='contract_name', how='left')\n",
    "        items_df = items_df.rename(columns={'most_probable_topic': 'clusterId'})\n",
    "        items_df['clusterId'] = items_df['clusterId'].fillna(0).astype(int)\n",
    "        num_clusters = int(max(items_df['clusterId'])) + 1\n",
    "        def one_hot(cluster_id, num_clusters):\n",
    "            vec = torch.zeros(num_clusters)\n",
    "            vec[int(cluster_id)] = 1\n",
    "            return vec\n",
    "        item_feat = torch.stack([one_hot(cid, num_clusters) for cid in items_df['clusterId']])\n",
    "        return item_feat\n",
    "        \n",
    "    # item_feat_clustering = get_item_feat_clustering(items_df)\n",
    "    ## item_feat_tfidf = get_item_feat_tfidf(items_df)\n",
    "    # item_feat_tfidf = np.load('dataset/tfidf_embeddings_100k.npy') # np.load('tfidf_embeddings_100k.npy')\n",
    "    # item_feat_tfidf = torch.from_numpy(item_feat_tfidf[:len(items_df['itemId'].unique())]).to(torch.float)\n",
    "    ## item_feat_sbert = get_item_feat_sbert(items_df)\n",
    "    item_feat_sbert = np.load('dataset/sbert_embeddings_full.npy') #np.load('sbert_embeddings_100k.npy')\n",
    "    item_feat_sbert = torch.from_numpy(item_feat_sbert[:len(items_df['itemId'].unique())]).to(torch.float)\n",
    "\n",
    "    items_ratings_df = items_ratings_df.rename(columns={'user': 'userId', 'item': 'itemId'})\n",
    "    unique_user_id, unique_item_id, edge_index_user_to_item = data_loader(items_ratings_df)\n",
    "    print('number of unique users', len(unique_user_id))\n",
    "    print('number of unique items', len(unique_item_id))\n",
    "    # TODO: create item_feat_df with itemId and item_feat tensor as columns\n",
    "    item_features_sbert_list = [feat.tolist() for feat in item_feat_sbert]\n",
    "    item_feat_sbert_df = pd.DataFrame({\n",
    "         'itemId': unique_item_id['mappedID'],\n",
    "         'itemFeature': item_features_sbert_list\n",
    "     })\n",
    "    item_feat_zeros = torch.zeros(len(unique_item_id), 768)\n",
    "    item_feats_dict = {\n",
    "        # 'item_feat_zeros': item_feat_zeros, \n",
    "        # 'item_feat_clustering': item_feat_clustering, \n",
    "        # 'item_feat_tfidf': item_feat_tfidf, \n",
    "         'item_feat_sbert': item_feat_sbert\n",
    "        }\n",
    "\n",
    "    return unique_user_id, unique_item_id, edge_index_user_to_item, items_df, item_feat_zeros, item_feats_dict, item_feat_sbert_df, items_ratings_df\n",
    "\n",
    "def calculate_sparsity(edge_index_user_to_item):\n",
    "        num_users = edge_index_user_to_item[0].max() + 1  # Assuming user IDs start from 0\n",
    "        num_items = edge_index_user_to_item[1].max() + 1  # Assuming item IDs start from 0\n",
    "        num_interactions = edge_index_user_to_item.shape[1]\n",
    "        total_possible_interactions = num_users * num_items\n",
    "        sparsity = 1 - (num_interactions / total_possible_interactions)\n",
    "\n",
    "        return sparsity\n",
    "\n",
    "if dataset_mode == 'contract':\n",
    "    unique_user_id, unique_item_id, edge_index_user_to_item, items_df, item_feat_zeros, item_feats_dict, item_feat_sbert_df, items_ratings_df = contract_loader()\n",
    "\n",
    "if dataset_mode == 'movie':\n",
    "    unique_user_id, unique_item_id, edge_index_user_to_item, items_df, item_feat_zeros, item_feats_dict, items_ratings_df = movie_loader_sampling_movie(1000)\n",
    "\n",
    "print('number of items', len(unique_item_id))\n",
    "print('number of users', len(unique_user_id))\n",
    "print('avg number of interactions per user', len(edge_index_user_to_item[0])/len(unique_user_id))\n",
    "# print(calculate_sparsity(edge_index_user_to_item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edge_index_user_to_item[0])\n",
    "len(unique_item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3042, 20])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_feat_zeros.shape\n",
    "item_feats_dict['item_feat_movielens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### TRAIN TEST GEN ##########\n",
    "\n",
    "def train_test_generator(unique_user_id, item_feat, edge_index_user_to_item):  \n",
    "    data = HeteroData()\n",
    "    data[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
    "    data[\"item\"].node_id = torch.arange(item_feat.shape[0])\n",
    "    data[\"item\"].x = item_feat\n",
    "    data[\"user\", \"rates\", \"item\"].edge_index = edge_index_user_to_item\n",
    "    # data = T.ToUndirected()(data)\n",
    "\n",
    "    transform = T.RandomLinkSplit(\n",
    "        num_val=0,\n",
    "        num_test=0.2,\n",
    "        disjoint_train_ratio=0.3,\n",
    "        neg_sampling_ratio=0, #2\n",
    "        add_negative_train_samples=False,\n",
    "        edge_types=(\"user\", \"rates\", \"item\"),\n",
    "        rev_edge_types=(\"item\", \"rev_rates\", \"user\"), \n",
    "    )\n",
    "    \n",
    "    train_data, _, test_data = transform(data)\n",
    "    return data, train_data, test_data\n",
    "\n",
    "def custom_train_test_generator(unique_user_id, unique_item_id, item_feat, edge_index_user_to_item, n_folds):\n",
    "\n",
    "    data = HeteroData()\n",
    "    data[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
    "    data[\"item\"].node_id = torch.arange(item_feat.shape[0])\n",
    "    data[\"item\"].x = item_feat\n",
    "    data[\"user\", \"rates\", \"item\"].edge_index = edge_index_user_to_item\n",
    "    data = T.ToUndirected()(data)\n",
    "\n",
    "    unique_user_id.sample(frac=1).reset_index(drop=True)\n",
    "    num_users = len(unique_user_id)\n",
    "    train_data, test_data = HeteroData(), HeteroData()\n",
    "    for data in [train_data, test_data]:\n",
    "        data[\"user\"].node_id = torch.arange(num_users)\n",
    "        data[\"item\"].node_id = torch.arange(item_feat.shape[0])\n",
    "        data[\"item\"].x = item_feat\n",
    "\n",
    "    if experiment == 'ucsp':\n",
    "        # train_users = unique_user_id[:int(0.8 * num_users)]\n",
    "        # test_users = unique_user_id[int(0.8 * num_users):]\n",
    "        # train_edges = edge_index_user_to_item[:, np.isin(edge_index_user_to_item[0], train_users)]\n",
    "        # test_edges = edge_index_user_to_item[:, np.isin(edge_index_user_to_item[0], test_users)]\n",
    "        # np.random.shuffle(train_edges.T)  # TODO: update theb shuffling using torch.randperm() method\n",
    "        # num_train_edges = train_edges.shape[1]\n",
    "        # disjoint_train_edges = train_edges[:, :int(0.3 * num_train_edges)]  # Disjoint part for embedding 240\n",
    "        # remaining_train_edges = train_edges[:, int(0.3 * num_train_edges):]  # Remaining for link prediction 560\n",
    "        raise NotImplementedError\n",
    "    elif experiment == 'icsp':\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        # Note:we can shuffle edges without considering the lables, since they are all ones before adding neg samples\n",
    "        def create_folds(edge_index_user_to_item, n_folds):\n",
    "            num_edges = edge_index_user_to_item.size(1)\n",
    "            batch_size = num_edges // n_folds\n",
    "            folds = []\n",
    "\n",
    "            for i in range(n_folds):\n",
    "                start_idx = i * batch_size\n",
    "                end_idx = num_edges if i == n_folds - 1 else start_idx + batch_size\n",
    "                test_edges = edge_index_user_to_item[:, start_idx:end_idx]\n",
    "                train_edges = torch.cat([edge_index_user_to_item[:, :start_idx], edge_index_user_to_item[:, end_idx:]], dim=1)\n",
    "                disjoint_size = int(0.3 * train_edges.shape[1])\n",
    "                disjoint_train_edges = train_edges[:, :disjoint_size]\n",
    "                remaining_train_edges = train_edges[:, disjoint_size:]\n",
    "                fold = {\n",
    "                    'train_edges': train_edges,\n",
    "                    'test_edges': test_edges,\n",
    "                    'disjoint_train_edges': disjoint_train_edges,\n",
    "                    'remaining_train_edges': remaining_train_edges\n",
    "                }\n",
    "                folds.append(fold)\n",
    "\n",
    "            return folds\n",
    "\n",
    "        indices = torch.randperm(edge_index_user_to_item.size(1))\n",
    "        edge_index_user_to_item = edge_index_user_to_item[:, indices]\n",
    "        folds = create_folds(edge_index_user_to_item, n_folds)\n",
    "\n",
    "    # def generate_negative_samples_fast(all_edges, test_users, num_items, num_neg_samples):\n",
    "    #     existing_edges = set(map(tuple, all_edges.t().numpy()))\n",
    "    #     min_user_id = test_users['mappedID'].min()\n",
    "    #     max_user_id = test_users['mappedID'].max()\n",
    "    #     neg_samples = []\n",
    "    #     while len(neg_samples) < num_neg_samples:\n",
    "    #         random_users = torch.randint(min_user_id, max_user_id, (num_neg_samples,))\n",
    "    #         random_items = torch.randint(0, num_items, (num_neg_samples,))\n",
    "    #         candidates = torch.stack([random_users, random_items], dim=1)\n",
    "    #         for candidate in candidates:\n",
    "    #             if tuple(candidate.tolist()) not in existing_edges:\n",
    "    #                 neg_samples.append(candidate.tolist())\n",
    "    #                 if len(neg_samples) == num_neg_samples:\n",
    "    #                     break\n",
    "    #     return torch.tensor(neg_samples)\n",
    "\n",
    "    # num_positive_samples = test_edges.shape[1]\n",
    "    # num_negative_samples = num_positive_samples * 3\n",
    "    # neg_samples = generate_negative_samples_fast(edge_index_user_to_item, test_users, len(unique_item_id), num_negative_samples)\n",
    "    # test_data[\"user\", \"rates\", \"item\"].edge_label_index = torch.cat([test_edges, neg_samples.t()], dim=1)\n",
    "    # test_data[\"user\", \"rates\", \"item\"].edge_label = torch.cat([torch.ones(num_positive_samples), torch.zeros(num_negative_samples)])\n",
    "    # test_data[\"user\", \"rates\", \"item\"].edge_index = test_data[\"user\", \"rates\", \"item\"].edge_label_index\n",
    "\n",
    "    return data, train_data, test_data, folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## NEG SAMPLIG #########\n",
    "# if experiment == 'ucsp' or experiment == 'icsp': \n",
    "#     test_data_temp = copy.deepcopy(test_data_csp)\n",
    "# test_data_all2all = copy.deepcopy(test_data_temp) # Now we're testing the Transform neg_sampeling instead of manually doing that\n",
    "# if experiment == 'add_social_edges': all_items = [item for item in all_items if item > len(all_users)]# which helps keep the social_edges in test and be evaluated or remove social_edges in test_set?\n",
    "\n",
    "def add_neg_samples(data, test_data):\n",
    "    test_data_temp = copy.deepcopy(test_data)\n",
    "    edge_index_zip = set(zip(data[\"user\", \"rates\", \"item\"].edge_index[0].numpy(), data[\"user\", \"rates\", \"item\"].edge_index[1].numpy()))\n",
    "    test_users = test_data_temp[\"user\", \"rates\", \"item\"].edge_label_index[0].unique().numpy()\n",
    "    all_items = data[\"user\", \"rates\", \"item\"].edge_index[1].unique().numpy()\n",
    "\n",
    "    new_edges = []\n",
    "    new_labels = []\n",
    "    edge_index_set = set(edge_index_zip)\n",
    "\n",
    "    for user_id in tqdm(test_users, total=len(test_users)):\n",
    "        count_user_new_edges = 0\n",
    "        random.shuffle(all_items)\n",
    "        for item_id in all_items:\n",
    "            if count_user_new_edges > each_user_all2all_new_edges:\n",
    "                break\n",
    "            if (user_id, item_id) not in edge_index_set:\n",
    "                count_user_new_edges += 1\n",
    "                new_edges.append((user_id, item_id))\n",
    "                new_labels.append(0)\n",
    "\n",
    "    test_data_all2all = copy.deepcopy(test_data_temp)\n",
    "    if new_edges:\n",
    "        new_edges_tensor = torch.tensor(new_edges, dtype=torch.int64).t().contiguous()\n",
    "        new_labels_tensor = torch.tensor(new_labels, dtype=torch.int64)\n",
    "        test_data_all2all[\"user\", \"rates\", \"item\"].edge_label_index = torch.cat((test_data_all2all[\"user\", \"rates\", \"item\"].edge_label_index, new_edges_tensor), dim=1)\n",
    "        test_data_all2all[\"user\", \"rates\", \"item\"].edge_label = torch.cat((test_data_all2all[\"user\", \"rates\", \"item\"].edge_label, new_labels_tensor), dim=0)\n",
    "\n",
    "    print('test edges shape BEFORE adding all possible user item pairs', test_data_temp[\"user\", \"rates\", \"item\"].edge_label_index.shape)\n",
    "    print('test edges shape AFTER adding all possible user item pairs', test_data_all2all[\"user\", \"rates\", \"item\"].edge_label_index.shape)\n",
    "    print('unique test users', len(test_data_all2all[\"user\", \"rates\", \"item\"].edge_label_index[0].unique()))\n",
    "    print('unique test items', len(test_data_all2all[\"user\", \"rates\", \"item\"].edge_label_index[1].unique()))\n",
    "\n",
    "    return test_data_all2all\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### GNN MODEL ##########\n",
    "def GNN_recommender(data, train_data):\n",
    "\n",
    "    # Define seed edges:\n",
    "    print('1')\n",
    "    edge_label_index = train_data[\"user\", \"rates\", \"item\"].edge_label_index\n",
    "    edge_label = train_data[\"user\", \"rates\", \"item\"].edge_label\n",
    "    print('2')\n",
    "    train_loader = LinkNeighborLoader(\n",
    "        data=train_data,\n",
    "        num_neighbors=[20, 10],\n",
    "        neg_sampling_ratio=2.0,\n",
    "        edge_label_index=((\"user\", \"rates\", \"item\"), edge_label_index),\n",
    "        edge_label=edge_label,\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    print('3')\n",
    "\n",
    "    class GNN(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels):\n",
    "            super().__init__()\n",
    "            self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "            self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "            x = F.relu(self.conv1(x, edge_index))\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return x\n",
    "    # Our final classifier applies the dot-product between source and destination\n",
    "    # node embeddings to drive edge-level predictions:\n",
    "    class Classifier(torch.nn.Module):\n",
    "        def forward(self, x_user: Tensor, x_item: Tensor, edge_label_index: Tensor) -> Tensor:\n",
    "            edge_feat_user = x_user[edge_label_index[0]] # Convert node embeddings to edge-level representations:\n",
    "            edge_feat_item = x_item[edge_label_index[1]]\n",
    "            scores = (edge_feat_user * edge_feat_item).sum(dim=-1)\n",
    "            return scores # Apply dot-product to get a prediction per supervision edge:\n",
    "        \n",
    "    class Model(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels):\n",
    "            super().__init__()\n",
    "            # Since the dataset does not come with rich features, we also learn two\n",
    "            # embedding matrices for users and items:\n",
    "            self.item_lin = torch.nn.Linear(data['item'].x.shape[1], hidden_channels)\n",
    "            self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
    "            self.item_emb = torch.nn.Embedding(data[\"item\"].num_nodes, hidden_channels)\n",
    "            # Instantiate homogeneous GNN:\n",
    "            self.gnn = GNN(hidden_channels)\n",
    "            # Convert GNN model into a heterogeneous variant:\n",
    "            self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "            self.classifier = Classifier()\n",
    "\n",
    "        def forward(self, data: HeteroData) -> Tensor:\n",
    "            x_dict = {\n",
    "            \"user\": self.user_emb(data[\"user\"].node_id),\n",
    "            \"item\": self.item_lin(data[\"item\"].x) + self.item_emb(data[\"item\"].node_id),\n",
    "            } \n",
    "            # `x_dict` holds feature matrices of all node types\n",
    "            # `edge_index_dict` holds all edge indices of all edge types\n",
    "            x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "            pred = self.classifier(\n",
    "                x_dict[\"user\"],\n",
    "                x_dict[\"item\"],\n",
    "                data[\"user\", \"rates\", \"item\"].edge_label_index,\n",
    "            )\n",
    "            return pred\n",
    "            \n",
    "    ########## TRAINING ##########\n",
    "    model = Model(hidden_channels=64)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: '{device}'\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    for epoch in range(1, 10):\n",
    "        total_loss = total_examples = 0\n",
    "        for sampled_data in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            sampled_data.to(device)\n",
    "            pred = model(sampled_data)\n",
    "            ground_truth = sampled_data[\"user\", \"rates\", \"item\"].edge_label\n",
    "            loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += float(loss) * pred.numel()\n",
    "            total_examples += pred.numel()\n",
    "\n",
    "        # TODO: Add the val_loader, keep the best model\n",
    "        print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")\n",
    "\n",
    "    ########## AUC EVAL VALIDATION #########\n",
    "    # edge_label_index = val_data[\"user\", \"rates\", \"item\"].edge_label_index\n",
    "    # edge_label = val_data[\"user\", \"rates\", \"item\"].edge_label\n",
    "    # # val_data has neg samples in it\n",
    "    # val_loader = LinkNeighborLoader(\n",
    "    #     data=val_data,\n",
    "    #     num_neighbors=[20, 10],\n",
    "    #     edge_label_index=((\"user\", \"rates\", \"item\"), edge_label_index),\n",
    "    #     edge_label=edge_label,\n",
    "    #     batch_size=3 * 128,\n",
    "    #     shuffle=False,\n",
    "    # )\n",
    "    # sampled_data = next(iter(val_loader))\n",
    "    # preds = []\n",
    "    # ground_truths = []\n",
    "    # for sampled_data in tqdm(val_loader):\n",
    "    #     with torch.no_grad():\n",
    "    #         sampled_data.to(device)\n",
    "    #         preds.append(model(sampled_data))\n",
    "    #         ground_truths.append(sampled_data[\"user\", \"rates\", \"item\"].edge_label)\n",
    "    # pred = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    # ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "    # auc = roc_auc_score(ground_truth, pred)\n",
    "    # print()\n",
    "    # print(f\"Validation AUC: {auc:.4f}\")\n",
    "    # return data, train_data, val_data, train_loader, val_loader, ground_truth, pred, test_data, model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GNN TRAINING ############\n",
    "#TODO: reactor below\n",
    "def gnn_train(dataset_mode, data, train_data, item_feats_dict, item_feat_to_model_name_dict):\n",
    "    models = {}\n",
    "\n",
    "    for item_feat_name, item_feat in item_feats_dict.items():\n",
    "        data['item'].x = item_feat\n",
    "        train_data['item'].x = item_feat\n",
    "        models[item_feat_to_model_name_dict[item_feat_name]] = GNN_recommender(data, train_data)\n",
    "\n",
    "    return models\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NOT-COMPLETED CSP EXPRIMENTS-OLD #######\n",
    "# Notel the problem with this approach: we simply remove items or users from testset (after generating test and train) that are in train. clearly removing part of user \n",
    "### CSP #### note: if the ratio==1, rerun from the first step\n",
    "if experiment == 'ucsp' or experiment == 'icsp':\n",
    "    def csp_test_gen(train_data, test_data, unique_data, entity_index, experiment_abbr):\n",
    "        train_data_unique_entities = set(train_data['user', 'rates', 'item'].edge_label_index[entity_index].unique().numpy())\n",
    "        unique_entities = set(unique_data['mappedID'].unique())\n",
    "        entities_not_in_train = unique_entities - train_data_unique_entities\n",
    "        print(len(unique_entities), len(entities_not_in_train))\n",
    "        mask = torch.tensor([entity in entities_not_in_train for entity in test_data[\"user\", \"rates\", \"item\"].edge_label_index[entity_index].numpy()])\n",
    "        \n",
    "        test_data_filtered = copy.deepcopy(test_data)\n",
    "        test_data_filtered[\"user\", \"rates\", \"item\"].edge_label_index = test_data_filtered[\"user\", \"rates\", \"item\"].edge_label_index[:, mask]\n",
    "        test_data_filtered[\"user\", \"rates\", \"item\"].edge_label = test_data_filtered[\"user\", \"rates\", \"item\"].edge_label[mask]\n",
    "        \n",
    "        ratio = len(test_data_filtered[\"user\", \"rates\", \"item\"].edge_label_index[entity_index]) / len(test_data[\"user\", \"rates\", \"item\"].edge_label_index[entity_index])\n",
    "        print(f'test to train ratio {experiment_abbr}', ratio)\n",
    "        \n",
    "        return test_data_filtered, ratio\n",
    "\n",
    "    test_data_csp, test_to_train_ratio_csp = csp_test_gen(\n",
    "        train_data, test_data, unique_user_id if experiment == 'ucsp' else unique_item_id, 0 if experiment == 'ucsp' else 1, 'CSP-user' if experiment == 'ucsp' else 'CSP-item'\n",
    "    )\n",
    "    print('test data len BEFOR CSP test gen:', len(test_data['user', 'rates', 'item'].edge_label_index[0]))\n",
    "    print('test data len AFTER CSP test gen:', len(test_data_csp['user', 'rates', 'item'].edge_label_index[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## GNN PRED ######### \n",
    "import time\n",
    "def gnn_pred(models, test_data_w_neg_samples, model_to_item_feat_dict):\n",
    "    \n",
    "    def _gnn_pred(model_gnn, test_data_w_neg_samples, item_feat):\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        test_data_w_neg_samples['item'].x = item_feat\n",
    "        test_loader_gnn = LinkNeighborLoader(\n",
    "            data=test_data_w_neg_samples,\n",
    "            num_neighbors=[20, 10],\n",
    "            edge_label_index=((\"user\", \"rates\", \"item\"), test_data_w_neg_samples[\"user\", \"rates\", \"item\"].edge_label_index),\n",
    "            edge_label=test_data_w_neg_samples[\"user\", \"rates\", \"item\"].edge_label,\n",
    "            batch_size= 3*128, # 3*128 TO calculate latency on inference time, use 17 as batch size, this will yield 10400 predictions that is near to MF number of preds (=10600)\n",
    "            shuffle=False,\n",
    "        )\n",
    "        sampled_data_gnn = next(iter(test_loader_gnn))\n",
    "        preds_gnn = []\n",
    "        ground_truths_gnn = []\n",
    "        model_gnn = model_gnn.to(device)\n",
    "        for sampled_data_gnn in tqdm(test_loader_gnn):\n",
    "            with torch.no_grad():\n",
    "                sampled_data_gnn.to(device)\n",
    "                preds_gnn.append(model_gnn(sampled_data_gnn))\n",
    "                ground_truths_gnn.append(sampled_data_gnn[\"user\", \"rates\", \"item\"].edge_label)\n",
    "        pred_gnn = torch.cat(preds_gnn, dim=0).cpu().numpy()\n",
    "        ground_truth_gnn = torch.cat(ground_truths_gnn, dim=0).cpu().numpy()\n",
    "        print('all ground truth len', len(ground_truth_gnn))\n",
    "        return pred_gnn, ground_truth_gnn\n",
    "    \n",
    "    preds = {}\n",
    "    for model_name, model in models.items():\n",
    "        if model_name not in preds:\n",
    "            preds[model_name] = {}\n",
    "\n",
    "\n",
    "        process = psutil.Process(os.getpid())\n",
    "        for model_name, model in models.items():\n",
    "            if model_name not in preds:\n",
    "                preds[model_name] = {}\n",
    "\n",
    "            start_time = time.time()\n",
    "            mem_usage_before = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "            preds[f'{model_name}'][f'pred_{model_name}'], preds[f'{model_name}'][f'ground_truth_{model_name}'] = _gnn_pred(model, test_data_w_neg_samples, model_to_item_feat_dict[f'{model_name}'])\n",
    "            end_time = time.time()\n",
    "            mem_usage_after = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "            total_memory_used = mem_usage_after - mem_usage_before\n",
    "\n",
    "            print(f'required time for {model_name} inference on testset:', end_time - start_time)\n",
    "            print(f'Total additional memory used for {model_name}:', total_memory_used, 'MB')\n",
    "\n",
    "            results_file = 'evaluation_times.txt'\n",
    "            with open(results_file, 'a') as file:\n",
    "                file.write(f'required time for {model_name} inference on testset: {end_time - start_time}\\n')\n",
    "                file.write(f'Total additional memory used for {model_name}: {total_memory_used} MB\\n')\n",
    "\n",
    "        # %memit pred_gnn_gen(device, test_data_w_neg_samples) %Uncomment to check the memory usage of GNN on inference\n",
    "\n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### MF DATA PREP  #############\n",
    "'''\n",
    "For LightFM models, we need a df of train and test data, \n",
    "but from GNN train/test generation, we have a HeteroData\n",
    "Here we turn a HeteroData to a DataFrame\n",
    "'''\n",
    "\n",
    "def mf_data_prep(test_data_w_neg_samples, train_data, unique_item_id):\n",
    "    def add_clusterID(df, contract_to_topic_df, unique_item_id):\n",
    "        item_to_topic = pd.Series(contract_to_topic_df['most_probable_topic'].values, index=contract_to_topic_df['contract_name']).to_dict()\n",
    "        mappedID_to_itemId = pd.Series(unique_item_id['itemId'].values, index=unique_item_id['mappedID']).to_dict()\n",
    "        df['item_name'] = df['item'].map(mappedID_to_itemId)\n",
    "        df['clusterId'] = df['item_name'].map(item_to_topic).fillna(0).astype(int)\n",
    "        df = df.drop(columns=['item_name'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    test_df_index = test_data_w_neg_samples['user', 'rates', 'item'].edge_label_index.numpy()\n",
    "    test_df_label = test_data_w_neg_samples['user', 'rates', 'item'].edge_label.numpy()\n",
    "\n",
    "    test_df_index = test_df_index.T \n",
    "    test_df_mf = pd.DataFrame(test_df_index, columns=['user', 'item'])\n",
    "    test_df_mf['rating'] = test_df_label\n",
    "\n",
    "\n",
    "    train_df_index = train_data['user', 'rates', 'item'].edge_label_index.numpy()\n",
    "    train_df_label = train_data['user', 'rates', 'item'].edge_label.numpy()\n",
    "    train_df_index = train_df_index.T \n",
    "    train_df_mf = pd.DataFrame(train_df_index, columns=['user', 'item'])\n",
    "    train_df_mf['rating'] = train_df_label\n",
    "\n",
    "    if dataset_mode == 'contract':\n",
    "        contract_to_topic_df = pd.read_parquet(\"dataset/contract_name_topic.parquet\")\n",
    "        train_df_mf= add_clusterID(train_df_mf, contract_to_topic_df, unique_item_id)\n",
    "        test_df_mf = add_clusterID(test_df_mf, contract_to_topic_df, unique_item_id)\n",
    "\n",
    "    return train_df_mf, test_df_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### MF & POP PRED  #############\n",
    "def pop_pred(preds, train_df_mf, test_df_mf):\n",
    "    if 'pop' not in preds:\n",
    "        preds['pop'] = {}\n",
    "    top_contracts = train_df_mf['item'].value_counts()[:20].index.tolist() #TODO: change to be determined dinamically based on k\n",
    "    test_df_mf['pred_pop'] = 0\n",
    "    test_df_mf.loc[test_df_mf['item'].isin(top_contracts), 'pred_pop'] = 1\n",
    "    preds['pop']['pred_pop'] = test_df_mf['pred_pop'].to_numpy()\n",
    "    preds['pop']['ground_truth_pop'] = test_df_mf['rating'].to_numpy()\n",
    "\n",
    "    return preds\n",
    "\n",
    "def mf_pred(preds, train_df_mf, test_df_mf, item_feat_sbert_df):\n",
    "    def initialize_dataset(train_df, test_df, additional_features=None):\n",
    "        dataset = Dataset()\n",
    "        user_ids = np.union1d(train_df['user'].unique(), test_df['user'].unique())\n",
    "        item_ids = np.union1d(train_df['item'].unique(), test_df['item'].unique())\n",
    "        if additional_features is not None:\n",
    "            dataset.fit(users=user_ids, items=item_ids, item_features=additional_features)\n",
    "        else:\n",
    "            dataset.fit(users=user_ids, items=item_ids)\n",
    "        return dataset\n",
    "\n",
    "    def build_model_and_predict(train_df, test_df, dataset, model_params, model_name, additional_features=None):\n",
    "        user_ids_mapping, _, item_ids_mapping, _ = dataset.mapping()\n",
    "\n",
    "        train_interactions, _ = dataset.build_interactions(\n",
    "            (row['user'], row['item'], row['rating']) for index, row in train_df.iterrows())\n",
    "\n",
    "        model = LightFM(**model_params)\n",
    "        if additional_features is not None:\n",
    "            item_features = dataset.build_item_features(\n",
    "                (x, [y]) for x, y in zip(train_df['item'], additional_features))\n",
    "            model.fit(train_interactions, item_features=item_features, epochs=30, num_threads=2)\n",
    "        else:\n",
    "            model.fit(train_interactions, epochs=30, num_threads=2)\n",
    "\n",
    "        test_df['predictions'] = 0.0\n",
    "\n",
    "        process = psutil.Process(os.getpid())\n",
    "        mem_before = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "        start_time = time.time()\n",
    "        for user, user_data in tqdm(test_df.groupby('user'), total=test_df['user'].nunique()):\n",
    "            user_id_internal = user_ids_mapping[user]\n",
    "            item_ids_internal = np.array([item_ids_mapping[item] for item in user_data['item']])\n",
    "            predictions = model.predict(user_id_internal, item_ids_internal)\n",
    "            test_df.loc[user_data.index, 'predictions'] = predictions\n",
    "\n",
    "        end_time = time.time()\n",
    "        mem_after = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "        mem_used = mem_after - mem_before\n",
    "        print(f'Inference time for {model_name}:', end_time - start_time)\n",
    "        print(f'Total additional memory used for {model_name}:', mem_used, \"MB\")\n",
    "\n",
    "        results_file = 'evaluation_times.txt'\n",
    "        with open(results_file, 'a') as file:\n",
    "            file.write(f'required time for {model_name} inference on testset: {end_time - start_time}\\n')\n",
    "            file.write(f'Total additional memory used for {model_name}: {mem_used} MB\\n')\n",
    "        \n",
    "\n",
    "        return test_df['predictions'].to_numpy(), test_df['rating'].to_numpy()\n",
    "\n",
    "    def cf_mf_pred_gen(train_df, test_df):\n",
    "        model_name = 'cf_mf'\n",
    "        dataset = initialize_dataset(train_df, test_df)\n",
    "        return build_model_and_predict(train_df, test_df, dataset, {'loss': 'warp'}, model_name)\n",
    "\n",
    "    def hybrid_mf_clustering_pred_gen(train_df, test_df):\n",
    "        model_name = 'hybrid_mf_clustering'\n",
    "        cluster_ids = np.union1d(train_df['clusterId'].unique(), test_df['clusterId'].unique())\n",
    "        dataset = initialize_dataset(train_df, test_df, additional_features=cluster_ids)\n",
    "        return build_model_and_predict(train_df, test_df, dataset, {'loss': 'warp'}, model_name, additional_features=train_df['clusterId'])\n",
    "\n",
    "    def hybrid_mf_sbert_pred_gen(train_df, test_df, item_feat_df):\n",
    "        model_name = 'hybrid_mf_sbert'\n",
    "        feature_range = range(len(item_feat_df['itemFeature'][0]))\n",
    "        dataset = initialize_dataset(train_df, test_df, additional_features=feature_range)\n",
    "        return build_model_and_predict(train_df, test_df, dataset, {'loss': 'warp'}, model_name, additional_features=feature_range)\n",
    "\n",
    "    # if 'cf_mf' not in preds: preds['cf_mf'] = {}\n",
    "    # preds['cf_mf']['pred_cf_mf'], preds['cf_mf']['ground_truth_cf_mf'] = cf_mf_pred_gen(train_df_mf, test_df_mf)\n",
    "\n",
    "    # if 'hybrid_mf_clustering' not in preds: preds['hybrid_mf_clustering'] = {}\n",
    "    # preds['hybrid_mf_clustering']['pred_hybrid_mf_clustering'], preds['hybrid_mf_clustering']['ground_truth_hybrid_mf_clustering'] = hybrid_mf_clustering_pred_gen(train_df_mf, test_df_mf)\n",
    "\n",
    "    if 'hybrid_mf_sbert' not in preds: preds['hybrid_mf_sbert'] = {}\n",
    "    preds['hybrid_mf_sbert']['pred_hybrid_mf_sbert'], preds['hybrid_mf_sbert']['ground_truth_hybrid_mf_sbert'] = hybrid_mf_sbert_pred_gen(train_df_mf, test_df_mf, item_feat_sbert_df)\n",
    "\n",
    "    return preds\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### PREDS EVAL #######\n",
    "def preds_eval(test_data_w_neg_samples, preds, fold_counter, model_variants):\n",
    "    def precision_at_k(user_id, sorted_indices, ground_truth, k):\n",
    "        top_k_indices = sorted_indices[:k]\n",
    "        top_k_labels = ground_truth[top_k_indices]\n",
    "        \n",
    "        # Check if there's any relevant item in the top k recommendations\n",
    "        hit = int(np.sum(top_k_labels) > 0)\n",
    "\n",
    "        return hit\n",
    "\n",
    "    def average_hit_at_k(k, ground_truth, pred, user_ids, edge_index, model_variant):\n",
    "        hits = []\n",
    "        for user_id in user_ids: \n",
    "            mask = edge_index[0] == user_id\n",
    "            filtered_pred = pred[mask]\n",
    "            filtered_ground_truth = ground_truth[mask]\n",
    "            sorted_indices = np.argsort(filtered_pred)[::-1]\n",
    "            # pop_hit = np.sum(filtered_pred[:np.sum(filtered_ground_truth == 1)] > 0) / (min(np.sum(filtered_ground_truth == 1), k) if np.sum(filtered_ground_truth == 1) != 0 else k)\n",
    "            # hits.append(precision_at_k(user_id, sorted_indices, filtered_ground_truth, k) if model_variant != 'pop' else pop_hit)\n",
    "            hits.append(precision_at_k(user_id, sorted_indices, filtered_ground_truth, k))\n",
    "            \n",
    "        return np.mean(hits)\n",
    "\n",
    "    def dcg_at_k(r, k):\n",
    "        r = np.asfarray(r)[:k]\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "\n",
    "    def ndcg_at_k(r, k):\n",
    "        dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
    "        if not dcg_max:\n",
    "            return 0.\n",
    "        return dcg_at_k(r, k) / dcg_max\n",
    "\n",
    "    def calculate_ndcg_at_k(k, ground_truth, pred, user_ids, edge_index):\n",
    "        ndcgs = []\n",
    "        for user_id in user_ids: # tqdm(user_ids, total=len(user_ids)):\n",
    "            mask = edge_index[0] == user_id\n",
    "            filtered_pred = pred[mask]\n",
    "            filtered_ground_truth = ground_truth[mask]\n",
    "            \n",
    "            # Sort by predicted score\n",
    "            sorted_indices = np.argsort(filtered_pred)[::-1]\n",
    "            sorted_ground_truth = filtered_ground_truth[sorted_indices]\n",
    "            \n",
    "            ndcgs.append(ndcg_at_k(sorted_ground_truth, k))\n",
    "            \n",
    "        return np.mean(ndcgs)\n",
    "\n",
    "    def average_precision_at_k(user_id, sorted_indices, ground_truth, k):\n",
    "        top_k_indices = sorted_indices[:k]\n",
    "        top_k_labels = ground_truth[top_k_indices]\n",
    "        \n",
    "        relevant_indices = np.where(top_k_labels > 0)[0]\n",
    "        num_relevant = len(relevant_indices)\n",
    "        \n",
    "        if num_relevant == 0:\n",
    "            return 0\n",
    "        \n",
    "        score = 0.0\n",
    "        for i in relevant_indices:\n",
    "            prec_at_i = np.sum(top_k_labels[:i+1]) / (i + 1)\n",
    "            score += prec_at_i\n",
    "        \n",
    "        return score / min(num_relevant, k)\n",
    "\n",
    "    def mean_ap_at_k(k, ground_truth, pred, user_ids, edge_index):\n",
    "        average_precisions = []\n",
    "        for user_id in user_ids: # tqdm(user_ids, total=len(user_ids)):\n",
    "            mask = edge_index[0] == user_id\n",
    "            filtered_pred = pred[mask]\n",
    "            filtered_ground_truth = ground_truth[mask]\n",
    "            sorted_indices = np.argsort(filtered_pred)[::-1]\n",
    "            \n",
    "            average_precisions.append(\n",
    "                average_precision_at_k(user_id, sorted_indices, filtered_ground_truth, k)\n",
    "            )\n",
    "            \n",
    "        return np.mean(average_precisions)\n",
    "\n",
    "    def _preds_eval(k_values, test_data_w_neg_samples, ground_truth, pred, model, results_file):\n",
    "        edge_index = test_data_w_neg_samples['user', 'rates', 'item'].edge_label_index\n",
    "        user_ids = np.unique(edge_index[0].numpy())\n",
    "\n",
    "        ## Tested shuffle below but did not have any effect ##\n",
    "        # permutation = np.random.permutation(edge_index.shape[1])\n",
    "        # edge_index_shuffled = edge_index[:, permutation]\n",
    "        # ground_truth_shuffled = ground_truth[permutation]\n",
    "        # pred_shuffled = pred[permutation]\n",
    "\n",
    "        with open(results_file, 'a') as file:  # 'a' for append, 'w' for write\n",
    "            file.write(f\"Results for {model}\\n\")\n",
    "\n",
    "            for k in k_values:\n",
    "                hit_at_k = average_hit_at_k(k, ground_truth, pred, user_ids, edge_index, model)\n",
    "                file.write(f\"HIT@{k}: {hit_at_k}\\n\")\n",
    "                print(f\"HIT@{k}: {hit_at_k}\")\n",
    "\n",
    "            for k in k_values:\n",
    "                map_at_k = mean_ap_at_k(k, ground_truth, pred, user_ids, edge_index)\n",
    "                file.write(f\"MAP@{k}: {map_at_k}\\n\")\n",
    "                print(f\"MAP@{k}: {map_at_k}\")\n",
    "\n",
    "            for k in k_values:\n",
    "                ndcg_result = calculate_ndcg_at_k(k, ground_truth, pred, user_ids, edge_index)\n",
    "                file.write(f\"NDCG@{k}: {ndcg_result}\\n\")\n",
    "                print(f\"NDCG@{k}: {ndcg_result}\")\n",
    "\n",
    "    # eval_loader = {\n",
    "    #     'pop': {\n",
    "    #        'ground_truth': ground_truth_pop,\n",
    "    #        'pred': pred_pop\n",
    "    #     },\n",
    "    #     'cf_mf': {\n",
    "    #        'ground_truth': ground_truth_cf_mf,\n",
    "    #        'pred': pred_cf_mf\n",
    "    #     },\n",
    "    #     'hybrid_mf_clustering': {\n",
    "    #         'ground_truth': ground_truth_hybrid_mf_clustering,\n",
    "    #         'pred': pred_hybrid_mf_clustering\n",
    "    #     },\n",
    "    #     'hybrid_mf_sbert': {\n",
    "    #        'ground_truth': ground_truth_hybrid_mf_sbert,\n",
    "    #        'pred': pred_hybrid_mf_sbert\n",
    "    #     },\n",
    "    #     'cf_gnn': {\n",
    "    #        'ground_truth': ground_truth_cf_gnn,\n",
    "    #        'pred': pred_cf_gnn\n",
    "    #     },\n",
    "    #     'hybrid_gnn_clustering': {\n",
    "    #         'ground_truth': ground_truth_hybrid_gnn_clustering,\n",
    "    #         'pred': pred_hybrid_gnn_clustering\n",
    "    #     },\n",
    "    #     'hybrid_gnn_tfidf': {\n",
    "    #         'ground_truth': ground_truth_hybrid_gnn_tfidf,\n",
    "    #         'pred': pred_hybrid_gnn_tfidf\n",
    "    #     },\n",
    "    #     'hybrid_gnn_sbert': {\n",
    "    #         'ground_truth': ground_truth_hybrid_gnn_sbert,\n",
    "    #         'pred': pred_hybrid_gnn_sbert\n",
    "    #     },\n",
    "\n",
    "    # }\n",
    "\n",
    "    results_file = 'evaluation_results.txt'\n",
    "    with open(results_file, 'a') as file:\n",
    "        file.write(f\"Fold counter: {fold_counter}\\n\")\n",
    "\n",
    "    for model in model_variants:\n",
    "        k_values = [1, 5, 10, 15, 20] if mode != 'debug' else [1, 5, 10, 15, 20]\n",
    "        _preds_eval(k_values, test_data_w_neg_samples, ground_truth=preds[model][f'ground_truth_{model}'], pred=preds[model][f'pred_{model}'], model=model, results_file=results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 435/435 [00:00<00:00, 835.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test edges shape BEFORE adding all possible user item pairs torch.Size([2, 2045])\n",
      "test edges shape AFTER adding all possible user item pairs torch.Size([2, 45980])\n",
      "unique test users 435\n",
      "unique test items 998\n",
      "1\n",
      "2\n",
      "3\n",
      "Device: 'cuda'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 56.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 50.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.4664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 50.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 0.3945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 50.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 0.3489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 50.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 0.3193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 48.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 0.3139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 50.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss: 0.2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 50.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss: 0.2866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 53.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss: 0.2744\n",
      "1\n",
      "2\n",
      "3\n",
      "Device: 'cuda'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 62.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.5665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 50.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 50.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 0.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 51.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 0.3494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 45.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 0.3293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 45.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 0.3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 50.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss: 0.2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 49.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss: 0.2893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 49.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss: 0.2744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 120/120 [00:00<00:00, 188.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ground truth len 45980\n",
      "required time for cf_gnn_movielens inference on testset: 0.6548764705657959\n",
      "Total additional memory used for cf_gnn_movielens: 0.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 120/120 [00:00<00:00, 191.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ground truth len 45980\n",
      "required time for hybrid_gnn_movielens inference on testset: 0.6379971504211426\n",
      "Total additional memory used for hybrid_gnn_movielens: 0.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 120/120 [00:00<00:00, 191.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ground truth len 45980\n",
      "required time for cf_gnn_movielens inference on testset: 0.6385502815246582\n",
      "Total additional memory used for cf_gnn_movielens: 0.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 120/120 [00:00<00:00, 191.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ground truth len 45980\n",
      "required time for hybrid_gnn_movielens inference on testset: 0.6388654708862305\n",
      "Total additional memory used for hybrid_gnn_movielens: 0.0 MB\n",
      "HIT@1: 0.3724137931034483\n",
      "HIT@5: 0.6850574712643678\n",
      "HIT@10: 0.825287356321839\n",
      "HIT@15: 0.871264367816092\n",
      "HIT@20: 0.9126436781609195\n",
      "MAP@1: 0.3724137931034483\n",
      "MAP@5: 0.4599457215836526\n",
      "MAP@10: 0.43975124854113634\n",
      "MAP@15: 0.42416017876452217\n",
      "MAP@20: 0.41409268790125875\n",
      "NDCG@1: 0.3724137931034483\n",
      "NDCG@5: 0.37709046547485753\n",
      "NDCG@10: 0.43365645325371144\n",
      "NDCG@15: 0.45975670818287395\n",
      "NDCG@20: 0.4830015244302661\n",
      "HIT@1: 0.34022988505747126\n",
      "HIT@5: 0.696551724137931\n",
      "HIT@10: 0.8045977011494253\n",
      "HIT@15: 0.8758620689655172\n",
      "HIT@20: 0.9126436781609195\n",
      "MAP@1: 0.34022988505747126\n",
      "MAP@5: 0.46128352490421465\n",
      "MAP@10: 0.44555361052466963\n",
      "MAP@15: 0.4296509105423371\n",
      "MAP@20: 0.42098544361068524\n",
      "NDCG@1: 0.34022988505747126\n",
      "NDCG@5: 0.3871149052904782\n",
      "NDCG@10: 0.42431519614388713\n",
      "NDCG@15: 0.4551715263460286\n",
      "NDCG@20: 0.4758251374915504\n"
     ]
    }
   ],
   "source": [
    "########## MAIN ############\n",
    "# data, train_data, test_data = train_test_generator(unique_user_id, item_feat_zeros, edge_index_user_to_item)\n",
    "# if dataset_mode == 'movie': model_to_item_feat_dict['hybrid_gnn_movielens'] #TODO: implemmet for movieLens\n",
    "\n",
    "if dataset_mode == 'contract':\n",
    "    model_to_item_feat_dict = {\n",
    "        # 'cf_gnn': item_feats_dict['item_feat_zeros'],\n",
    "        # 'hybrid_gnn_clustering': item_feats_dict['item_feat_clustering'],\n",
    "        # 'hybrid_gnn_tfidf': item_feats_dict['item_feat_tfidf'],\n",
    "        # 'hybrid_gnn_sbert': item_feats_dict['item_feat_sbert'],\n",
    "    }\n",
    "\n",
    "    item_feat_to_model_name_dict = {\n",
    "        # 'item_feat_zeros': 'cf_gnn',\n",
    "        # 'item_feat_clustering': 'hybrid_gnn_clustering',\n",
    "        # 'item_feat_tfidf': 'hybrid_gnn_tfidf',\n",
    "        # 'item_feat_sbert': 'hybrid_gnn_sbert'\n",
    "    }\n",
    "\n",
    "    model_variants = ['cf_mf'] # ,'cf_mf',  'hybrid_mf_clustering', 'hybrid_mf_sbert', 'cf_gnn', 'hybrid_gnn_clustering', 'hybrid_gnn_sbert']\n",
    "    \n",
    "else:\n",
    "    model_to_item_feat_dict = {\n",
    "        'cf_gnn_movielens': item_feats_dict['item_feat_zeros'],\n",
    "        'hybrid_gnn_movielens': item_feats_dict['item_feat_movielens'],\n",
    "    }\n",
    "\n",
    "    item_feat_to_model_name_dict = {\n",
    "        'item_feat_zeros': 'cf_gnn_movielens',\n",
    "        'item_feat_movielens': 'hybrid_gnn_movielens',\n",
    "    }\n",
    "\n",
    "    model_variants = ['cf_gnn_movielens', 'hybrid_gnn_movielens']\n",
    "    # model_variants = ['hybrid_gnn_movielens']\n",
    "\n",
    "n_folds= 5\n",
    "data, train_data, test_data, folds = custom_train_test_generator(unique_user_id, unique_item_id, item_feat_zeros, edge_index_user_to_item, n_folds)\n",
    "\n",
    "fold_counter = 1\n",
    "for fold in folds:\n",
    "    train_data[\"user\", \"rates\", \"item\"].edge_index = fold['remaining_train_edges']\n",
    "    train_data[\"user\", \"rates\", \"item\"].edge_label_index = fold['disjoint_train_edges']\n",
    "    train_data[\"user\", \"rates\", \"item\"].edge_label = torch.ones(len(train_data[\"user\", \"rates\", \"item\"].edge_label_index[0]))\n",
    "\n",
    "    test_data[\"user\", \"rates\", \"item\"].edge_index = fold['train_edges'] # TODO: check the correctness\n",
    "    test_data[\"user\", \"rates\", \"item\"].edge_label_index = fold['test_edges']\n",
    "    test_data[\"user\", \"rates\", \"item\"].edge_label = torch.ones(len(test_data[\"user\", \"rates\", \"item\"].edge_label_index[0]))\n",
    "\n",
    "    train_data = T.ToUndirected()(train_data)\n",
    "    test_data = T.ToUndirected()(test_data)\n",
    "    data = T.ToUndirected()(data) # Note: not sure why we need to have this here\n",
    "    test_data_w_neg_samples = add_neg_samples(data, test_data)\n",
    "    preds = {}\n",
    "\n",
    "    models = gnn_train(dataset_mode, data, train_data, item_feats_dict, item_feat_to_model_name_dict)\n",
    "    preds = gnn_pred(models, test_data_w_neg_samples, model_to_item_feat_dict)\n",
    "\n",
    "    #TODO: Make the MF pred/train separate now they all will be computed together\n",
    "    if dataset_mode == 'contract':\n",
    "        train_df_mf, test_df_mf = mf_data_prep(test_data_w_neg_samples, train_data, unique_item_id)\n",
    "        preds = pop_pred(preds, train_df_mf, test_df_mf)\n",
    "        preds = mf_pred(preds, train_df_mf, test_df_mf, item_feat_sbert_df)\n",
    "\n",
    "    preds_eval(test_data_w_neg_samples, preds, fold_counter, model_variants)\n",
    "    fold_counter += 1\n",
    "    break\n",
    "\n",
    "\n",
    "#SOCIAL EDGES ABLEATION EXPERIMENT#\n",
    "# def add_social_edges(edge_index_user_to_item, unique_user_id, unique_item_id, items_ratings_df, item_feat):\n",
    "#     unique_item_id = unique_item_id.copy()\n",
    "#     # Define the filename where the data will be saved\n",
    "#     filename = 'dataset/saved_social_edges_100k.pkl'\n",
    "\n",
    "#     # Check if the file exists\n",
    "#     if os.path.exists(filename):\n",
    "#         # If it does, load the data and return it\n",
    "#         with open(filename, 'rb') as f:\n",
    "#             unique_user_id, unique_item_id_w_users, edge_index_user_to_item, item_feat = pickle.load(f)\n",
    "#         print('Data loaded from file')\n",
    "#     else:\n",
    "#         user_transactions_df = pd.read_parquet('dataset/user_transactions.parquet')\n",
    "#         contract_addresses = pd.read_parquet('dataset/contract_addresses.parquet')\n",
    "#         contract_set = set(contract_addresses['address'])\n",
    "\n",
    "#         # Shifting item_ids\n",
    "#         edge_index_user_to_item[1] = edge_index_user_to_item[1] + len(edge_index_user_to_item[0].unique())\n",
    "#         unique_item_id['mappedID'] = unique_item_id['mappedID'] + len(edge_index_user_to_item[0].unique())\n",
    "#         #Adding user_ids to item_ids since now users can be an item too #TODO if the GNN performance turned to be bad, just add 'to' user addresses to both item_feat and unique_item_ids\n",
    "#         unique_item_id_w_users = pd.concat([unique_user_id.rename(columns={'userId': 'entityId'}), unique_item_id.rename(columns={'itemId': 'entityId'})], axis=0)\n",
    "#         user_feat = torch.zeros((len(edge_index_user_to_item[0].unique()), item_feat.shape[1]))\n",
    "#         item_feat= torch.cat([user_feat, item_feat], dim=0) # Why don't we adding item_feat to user_feat?\n",
    "\n",
    "#         # unique_item_id_w_users['type'] = 'user' or 'item'\n",
    "\n",
    "#         users = items_ratings_df['userId'].unique()\n",
    "\n",
    "#         print('edge index shape before adding social edges:', edge_index_user_to_item.shape)\n",
    "#         count = 0\n",
    "#         #note there is a 200k constraint, delete it\n",
    "#         for i, interaction in tqdm(user_transactions_df.iterrows(), total=len(user_transactions_df)):\n",
    "#             if interaction['from'] not in contract_set and interaction['to'] not in contract_set and interaction['from'] in users and interaction['to'] in users:\n",
    "#                 if interaction['from'] == interaction['to']: continue\n",
    "#                 from_user_id = unique_item_id_w_users[unique_item_id_w_users['entityId'] == interaction['from']]['mappedID'].iloc[0]\n",
    "#                 to_user_id = unique_item_id_w_users[unique_item_id_w_users['entityId'] == interaction['to']]['mappedID'].iloc[0]\n",
    "#                 social_edge = torch.tensor([[from_user_id], \n",
    "#                                             [to_user_id]], dtype=torch.int64)\n",
    "#                 edge_index_user_to_item = torch.cat([edge_index_user_to_item, social_edge], dim=1)\n",
    "#                 # count += 1\n",
    "#                 # if count % 5 == 0: break\n",
    "#         print('edge index shape after adding social edges:', edge_index_user_to_item.shape)\n",
    "#         del user_transactions_df\n",
    "#         del contract_addresses\n",
    "#         del contract_set\n",
    "#         import gc\n",
    "#         gc.collect()\n",
    "\n",
    "#         #uncomment below\n",
    "#         with open(filename, 'wb') as f:\n",
    "#             pickle.dump((unique_user_id, unique_item_id_w_users, edge_index_user_to_item, item_feat), f)\n",
    "#         print('social edges saved to dataset/saved_social_edges_100k.pkl')\n",
    "    \n",
    "#     return unique_user_id, unique_item_id_w_users, edge_index_user_to_item, item_feat\n",
    "# if experiment == 'add_social_edges':\n",
    "#     #TODO: if wanna use the social edges, need to pass the arguments\n",
    "#     unique_user_id_w_social, unique_item_id_w_social, edge_index_user_to_item_w_social, item_feat_w_social = add_social_edges(edge_index_user_to_item, unique_user_id, unique_item_id, items_ratings_df, item_feat)\n",
    "#     data, train_data, test_data = _train_test_generator(unique_user_id_w_social, item_feat_w_social, edge_index_user_to_item_w_social)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DIVERSITY EXPERIMENT ##############\n",
    "model_variants = ['mfn', 'mfc', 'pop']\n",
    "eval_loader = {\n",
    "    # 'gnn': {\n",
    "    #     'ground_truth': ground_truth_gnn,\n",
    "    #     'pred': pred_gnn\n",
    "    # },\n",
    "    'pop': {\n",
    "        'ground_truth': ground_truth_pop,\n",
    "        'pred': pred_pop\n",
    "    },\n",
    "    'mfn': {\n",
    "        'ground_truth': ground_truth_mfn,\n",
    "        'pred': pred_mfn\n",
    "    },\n",
    "    'mfc': {\n",
    "        'ground_truth': ground_truth_mfc,\n",
    "        'pred': pred_mfc\n",
    "    },\n",
    "\n",
    "}\n",
    "for model_variant_eval in model_variants:\n",
    "    k_values = [1, 5, 10, 15, 20] if mode != 'debug' else [1, 5, 10, 15, 20]\n",
    "if experiment == 'diversity':\n",
    "    edge_index = test_data_all2all['user', 'rates', 'item'].edge_label_index\n",
    "    user_ids = np.unique(edge_index[0].numpy())\n",
    "\n",
    "    for model_variant_eval in model_variants:\n",
    "        pred = eval_loader[model_variant_eval]['pred']\n",
    "        ground_truth = eval_loader[model_variant_eval]['ground_truth']\n",
    "\n",
    "        for k in k_values:\n",
    "            recs_list = set()\n",
    "            for user_id in user_ids: # tqdm(user_ids, total=len(user_ids)):\n",
    "                mask = edge_index[0] == user_id\n",
    "                filtered_pred = pred[mask]\n",
    "                filtered_items = edge_index[1][mask]\n",
    "                sorted_indices = np.argsort(filtered_pred)[::-1]\n",
    "                top_k_indices = sorted_indices[:k]\n",
    "                top_k_indices = top_k_indices.copy()\n",
    "                top_k_items = filtered_items[top_k_indices].numpy()\n",
    "                recs_list.update(top_k_items)\n",
    "\n",
    "            diversity_at_k = len(recs_list) / len(np.unique(edge_index[1].numpy()))\n",
    "            print(f'Item coverage diversity for {model_variant_eval} @{k}:', diversity_at_k)\n",
    "        \n",
    "        for k in k_values:\n",
    "            users_with_relevant_recs = set()\n",
    "            \n",
    "            for user_id in user_ids: # tqdm(user_ids, total=len(user_ids)):\n",
    "                mask = edge_index[0] == user_id\n",
    "                filtered_pred = pred[mask]\n",
    "                sorted_indices = np.argsort(filtered_pred)[::-1]\n",
    "                top_k_indices = sorted_indices[:k]\n",
    "                filtered_ground_truth = ground_truth[mask] \n",
    "                relevant_recs = filtered_ground_truth[top_k_indices] \n",
    "                \n",
    "                if np.sum(relevant_recs) > 0:  # At least one relevant recommendation\n",
    "                    users_with_relevant_recs.add(user_id)\n",
    "            \n",
    "            user_coverage_at_k = len(users_with_relevant_recs) / len(user_ids)\n",
    "            print(f'User coverage for {model_variant_eval} @{k}:', user_coverage_at_k)\n",
    "\n",
    "    #######  Intra-List Diversity #######\n",
    "    # TODO: Based on item_feat define the compute_dissimilarity method\n",
    "    # for k in k_values:\n",
    "    #     avg_dissimilarity = []\n",
    "        \n",
    "    #     for user_id in tqdm(user_ids, total=len(user_ids)):\n",
    "    #         mask = edge_index[0] == user_id\n",
    "    #         filtered_pred = pred[mask]\n",
    "    #         filtered_items = edge_index[1][mask]\n",
    "    #         sorted_indices = np.argsort(filtered_pred)[::-1]\n",
    "    #         top_k_indices = sorted_indices[:k]\n",
    "    #         top_k_items = filtered_items[top_k_indices].numpy()\n",
    "            \n",
    "    #         dissimilarity_sum = 0\n",
    "    #         for i in range(len(top_k_items)):\n",
    "    #             for j in range(i+1, len(top_k_items)):\n",
    "    #                 dissimilarity_sum += compute_dissimilarity(top_k_items[i], top_k_items[j])\n",
    "            \n",
    "    #         if k > 1:\n",
    "    #             avg_pairwise_dissimilarity = 2 * dissimilarity_sum / (k * (k - 1))\n",
    "    #             avg_dissimilarity.append(avg_pairwise_dissimilarity)\n",
    "        \n",
    "    #     intra_list_diversity_at_k = np.mean(avg_dissimilarity)\n",
    "    #     print(f'Intra-list diversity for {model_mode_eval} @{k}:', intra_list_diversity_at_k)\n",
    "\n",
    "'''\n",
    "Item coverage diversity for gnn @1: 0.1974024375230826\n",
    "Item coverage diversity for gnn @5: 0.6526529607287948\n",
    "Item coverage diversity for gnn @10: 0.9267512002954573\n",
    "Item coverage diversity for gnn @15: 0.9996922319340146\n",
    "Item coverage diversity for gnn @20: 1.0\n",
    "User coverage for gnn @1: 0.5559827456864216\n",
    "User coverage for gnn @5: 0.6452550637659414\n",
    "User coverage for gnn @10: 0.6614778694673669\n",
    "User coverage for gnn @15: 0.6639159789947486\n",
    "User coverage for gnn @20: 0.6641035258814704\n",
    "Item coverage diversity for mfn @1: 0.18576880462883172\n",
    "Item coverage diversity for mfn @5: 0.5387172227009726\n",
    "Item coverage diversity for mfn @10: 0.9447864089622061\n",
    "Item coverage diversity for mfn @15: 0.9996922319340146\n",
    "Item coverage diversity for mfn @20: 0.999938446386803\n",
    "User coverage for mfn @1: 0.5041260315078769\n",
    "User coverage for mfn @5: 0.5982745686421606\n",
    "User coverage for mfn @10: 0.6395348837209303\n",
    "User coverage for mfn @15: 0.6611965491372843\n",
    "User coverage for mfn @20: 0.6641035258814704\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages for pop:\n",
      "  HIT@1: 0.525118857452899\n",
      "  HIT@5: 0.5316305610009956\n",
      "  HIT@10: 0.5316305610009956\n",
      "  HIT@15: 0.5316305610009956\n",
      "  HIT@20: 0.5316305610009956\n",
      "  MAP@1: 0.525118857452899\n",
      "  MAP@5: 0.5281673178247572\n",
      "  MAP@10: 0.5281673178247572\n",
      "  MAP@15: 0.5281619622120752\n",
      "  MAP@20: 0.5281053808132493\n",
      "  NDCG@1: 0.525118857452899\n",
      "  NDCG@5: 0.37704209968400487\n",
      "  NDCG@10: 0.37261677412328975\n",
      "  NDCG@15: 0.37255288683678045\n",
      "  NDCG@20: 0.37258370108423394\n",
      "Averages for cf_mf:\n",
      "  HIT@1: 0.6285209435069636\n",
      "  HIT@5: 0.7775464200416244\n",
      "  HIT@10: 0.8261171064235355\n",
      "  HIT@15: 0.8538628439358449\n",
      "  HIT@20: 0.8739593878706737\n",
      "  MAP@1: 0.6285209435069636\n",
      "  MAP@5: 0.669935836518043\n",
      "  MAP@10: 0.6513895927066209\n",
      "  MAP@15: 0.6360664839135294\n",
      "  MAP@20: 0.6237741528266876\n",
      "  NDCG@1: 0.6285209435069636\n",
      "  NDCG@5: 0.5523424146053588\n",
      "  NDCG@10: 0.5729463227314244\n",
      "  NDCG@15: 0.5893046464487621\n",
      "  NDCG@20: 0.600724423953853\n",
      "Averages for hybrid_mf_clustering:\n",
      "  HIT@1: 0.5942786023314859\n",
      "  HIT@5: 0.7391360389596634\n",
      "  HIT@10: 0.7878674950427289\n",
      "  HIT@15: 0.8198375515272057\n",
      "  HIT@20: 0.8398231969159189\n",
      "  MAP@1: 0.5942786023314859\n",
      "  MAP@5: 0.6382874458898771\n",
      "  MAP@10: 0.6218326082111474\n",
      "  MAP@15: 0.6058944979098821\n",
      "  MAP@20: 0.5942881992492625\n",
      "  NDCG@1: 0.5942786023314859\n",
      "  NDCG@5: 0.5050745861610264\n",
      "  NDCG@10: 0.521957283146615\n",
      "  NDCG@15: 0.5393028599567548\n",
      "  NDCG@20: 0.550175870417585\n",
      "Averages for hybrid_mf_sbert:\n",
      "  HIT@1: 0.5897010196210857\n",
      "  HIT@5: 0.7749642648274846\n",
      "  HIT@10: 0.8261728379806257\n",
      "  HIT@15: 0.8555537111825589\n",
      "  HIT@20: 0.8754448442790403\n",
      "  MAP@1: 0.5897010196210857\n",
      "  MAP@5: 0.6469297308318155\n",
      "  MAP@10: 0.6287104264774347\n",
      "  MAP@15: 0.6137365241051038\n",
      "  MAP@20: 0.6011732524600588\n",
      "  NDCG@1: 0.5897010196210857\n",
      "  NDCG@5: 0.5328424822239467\n",
      "  NDCG@10: 0.5559233652502975\n",
      "  NDCG@15: 0.5728234618816165\n",
      "  NDCG@20: 0.5846100937113161\n",
      "Averages for cf_gnn:\n",
      "  HIT@1: 0.4592783012687323\n",
      "  HIT@5: 0.7013668991664046\n",
      "  HIT@10: 0.7994032867287656\n",
      "  HIT@15: 0.8523121452382995\n",
      "  HIT@20: 0.8865504639671358\n",
      "  MAP@1: 0.4592783012687323\n",
      "  MAP@5: 0.5313681779011328\n",
      "  MAP@10: 0.5176225115112261\n",
      "  MAP@15: 0.5037948108198134\n",
      "  MAP@20: 0.49115765768113473\n",
      "  NDCG@1: 0.4592783012687323\n",
      "  NDCG@5: 0.4356833795623952\n",
      "  NDCG@10: 0.47424264345709216\n",
      "  NDCG@15: 0.4993013446009618\n",
      "  NDCG@20: 0.5172239158321921\n",
      "Averages for hybrid_gnn_clustering:\n",
      "  HIT@1: 0.620613595919403\n",
      "  HIT@5: 0.820857773327328\n",
      "  HIT@10: 0.8799055573342538\n",
      "  HIT@15: 0.9076995226342065\n",
      "  HIT@20: 0.926430627007577\n",
      "  MAP@1: 0.620613595919403\n",
      "  MAP@5: 0.6763107453670718\n",
      "  MAP@10: 0.6552965190840607\n",
      "  MAP@15: 0.6380450490259326\n",
      "  MAP@20: 0.62471771984805\n",
      "  NDCG@1: 0.620613595919403\n",
      "  NDCG@5: 0.5778266480064115\n",
      "  NDCG@10: 0.6110585447931574\n",
      "  NDCG@15: 0.6330678944710147\n",
      "  NDCG@20: 0.6480712347281634\n",
      "Averages for hybrid_gnn_tfidf:\n",
      "  HIT@1: 0.64046779706439\n",
      "  HIT@5: 0.8385349271567858\n",
      "  HIT@10: 0.8940847202352772\n",
      "  HIT@15: 0.9201345466835423\n",
      "  HIT@20: 0.9379788981624192\n",
      "  MAP@1: 0.64046779706439\n",
      "  MAP@5: 0.6952361713783178\n",
      "  MAP@10: 0.6729542952434454\n",
      "  MAP@15: 0.655858778087523\n",
      "  MAP@20: 0.642633640962057\n",
      "  NDCG@1: 0.64046779706439\n",
      "  NDCG@5: 0.6006016574825849\n",
      "  NDCG@10: 0.6344298537054234\n",
      "  NDCG@15: 0.6567704405819985\n",
      "  NDCG@20: 0.6714411947961096\n",
      "Averages for hybrid_gnn_sbert:\n",
      "  HIT@1: 0.6521313756343644\n",
      "  HIT@5: 0.844923646375974\n",
      "  HIT@10: 0.9049438379903529\n",
      "  HIT@15: 0.931004197878043\n",
      "  HIT@20: 0.94855835882436\n",
      "  MAP@1: 0.6521313756343644\n",
      "  MAP@5: 0.7032662825528271\n",
      "  MAP@10: 0.6789432441842989\n",
      "  MAP@15: 0.6604093113137247\n",
      "  MAP@20: 0.6462018444517219\n",
      "  NDCG@1: 0.6521313756343644\n",
      "  NDCG@5: 0.6069774795195586\n",
      "  NDCG@10: 0.6428766452308203\n",
      "  NDCG@15: 0.6656726744433817\n",
      "  NDCG@20: 0.6810761639913994\n"
     ]
    }
   ],
   "source": [
    "######## AVG FOLDSS RESULTS #########\n",
    "def read_results(file_path):\n",
    "    # Initialize dictionaries to store sums and counts for each metric for both categories\n",
    "    sums = {'pop': {}, 'cf_mf': {}, 'hybrid_mf_clustering': {}, 'hybrid_mf_sbert': {}, 'cf_gnn': {}, 'hybrid_gnn_clustering': {}, 'hybrid_gnn_tfidf': {}, 'hybrid_gnn_sbert': {}}\n",
    "    counts = {'pop': {}, 'cf_mf': {}, 'hybrid_mf_clustering': {}, 'hybrid_mf_sbert': {}, 'cf_gnn': {}, 'hybrid_gnn_clustering': {}, 'hybrid_gnn_tfidf': {}, 'hybrid_gnn_sbert': {}}\n",
    "    current_category = None\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Check for category\n",
    "            if \"Results for\" in line:\n",
    "                current_category = line.split()[-1]\n",
    "\n",
    "            # Check if the line contains a metric\n",
    "            elif line and \"HIT@\" in line or \"MAP@\" in line or \"NDCG@\" in line:\n",
    "                parts = line.split(':')\n",
    "                metric = parts[0].strip()\n",
    "                value = float(parts[1].strip())\n",
    "\n",
    "                # Update the sum and count for the metric in the current category\n",
    "                if metric not in sums[current_category]:\n",
    "                    sums[current_category][metric] = 0\n",
    "                    counts[current_category][metric] = 0\n",
    "                sums[current_category][metric] += value\n",
    "                counts[current_category][metric] += 1\n",
    "\n",
    "    # Calculate averages for each category\n",
    "    averages = {category: {metric: sums[category][metric] / counts[category][metric] \n",
    "                           for metric in sums[category]} \n",
    "                for category in sums}\n",
    "\n",
    "    return averages\n",
    "\n",
    "file_path = 'evaluation_results_Nov28_055001.txt'  # Replace with your file path\n",
    "averages = read_results(file_path)\n",
    "\n",
    "# Print the averages for each category\n",
    "for category in averages:\n",
    "    print(f\"Averages for {category}:\")\n",
    "    for metric, avg in averages[category].items():\n",
    "        print(f\"  {metric}: {avg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
